{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet 50 analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.17.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.25.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\swadh\\appdata\\roaming\\python\\python311\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\swadh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow\n",
    "%pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 556 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet50_preprocess_input\n",
    "\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('C:/Users/swadh/OneDrive/Desktop/crimedetection/resnet.h5')\n",
    "\n",
    "# Define the test data generator\n",
    "IMAGE_RESIZE = (240, 320)\n",
    "BATCH_SIZE_TESTING = 32\n",
    "\n",
    "def preprocess_input(img):\n",
    "    # Apply ResNet50 specific preprocessing\n",
    "    img = resnet50_preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "test_data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "test_generator = test_data_generator.flow_from_directory(\n",
    "    r'C:\\Users\\swadh\\OneDrive\\Desktop\\crimedetection',  # Path to the parent directory of test_crime and test_normal\n",
    "    target_size=IMAGE_RESIZE,\n",
    "    batch_size=BATCH_SIZE_TESTING,\n",
    "    class_mode='binary',\n",
    "    classes=['test_crime', 'test_normal'],  # Ensure these match your folder names\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\swadh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  test_crime       0.98      0.97      0.98       330\n",
      " test_normal       0.95      0.98      0.97       226\n",
      "\n",
      "    accuracy                           0.97       556\n",
      "   macro avg       0.97      0.97      0.97       556\n",
      "weighted avg       0.97      0.97      0.97       556\n",
      "\n",
      "[[319  11]\n",
      " [  5 221]]\n"
     ]
    }
   ],
   "source": [
    "# Predict the labels for the test data\n",
    "predictions = model.predict(test_generator, steps=test_generator.samples // test_generator.batch_size + 1)\n",
    "predicted_classes = np.where(predictions > 0.5, 1, 0)\n",
    "\n",
    "# Get the true labels\n",
    "true_classes = test_generator.classes\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "print(report)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgg16 model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 556 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input as vgg16_preprocess_input\n",
    "def preprocess_input(img):\n",
    "    img = vgg16_preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('C:/Users/swadh/OneDrive/Desktop/crimedetection/vgg16.h5')\n",
    "\n",
    "# Define the test data generator\n",
    "IMAGE_RESIZE = (240, 320)\n",
    "BATCH_SIZE_TESTING = 32\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "test_generator = test_data_generator.flow_from_directory(\n",
    "    r'C:\\Users\\swadh\\OneDrive\\Desktop\\crimedetection',  # Path to the parent directory of test_crime and test_normal\n",
    "    target_size=IMAGE_RESIZE,\n",
    "    batch_size=BATCH_SIZE_TESTING,\n",
    "    class_mode='binary',\n",
    "    classes=['test_crime', 'test_normal'],  # Ensure these match your folder names\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\swadh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 6s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  test_crime       0.97      0.98      0.98       330\n",
      " test_normal       0.97      0.96      0.97       226\n",
      "\n",
      "    accuracy                           0.97       556\n",
      "   macro avg       0.97      0.97      0.97       556\n",
      "weighted avg       0.97      0.97      0.97       556\n",
      "\n",
      "[[324   6]\n",
      " [  9 217]]\n"
     ]
    }
   ],
   "source": [
    "# Predict the labels for the test data\n",
    "predictions = model.predict(test_generator, steps=test_generator.samples // test_generator.batch_size + 1)\n",
    "predicted_classes = np.where(predictions > 0.5, 1, 0)\n",
    "\n",
    "# Get the true labels\n",
    "true_classes = test_generator.classes\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "print(report)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgg19 model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input as vgg19_preprocess_input\n",
    "# Define the preprocessing function for VGG19\n",
    "def preprocess_input(img):\n",
    "    img = vgg19_preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 556 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('C:/Users/swadh/OneDrive/Desktop/crimedetection/vgg19.h5')\n",
    "\n",
    "# Define the test data generator\n",
    "IMAGE_RESIZE = (240, 320)\n",
    "BATCH_SIZE_TESTING = 32\n",
    "\n",
    "test_data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "test_generator = test_data_generator.flow_from_directory(\n",
    "    r'C:\\Users\\swadh\\OneDrive\\Desktop\\crimedetection',  # Path to the parent directory of test_crime and test_normal\n",
    "    target_size=IMAGE_RESIZE,\n",
    "    batch_size=BATCH_SIZE_TESTING,\n",
    "    class_mode='binary',\n",
    "    classes=['test_crime', 'test_normal'],  # Ensure these match your folder names\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\swadh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 8s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  test_crime       0.98      0.97      0.98       330\n",
      " test_normal       0.96      0.97      0.96       226\n",
      "\n",
      "    accuracy                           0.97       556\n",
      "   macro avg       0.97      0.97      0.97       556\n",
      "weighted avg       0.97      0.97      0.97       556\n",
      "\n",
      "[[321   9]\n",
      " [  7 219]]\n"
     ]
    }
   ],
   "source": [
    "# Predict the labels for the test data\n",
    "predictions = model.predict(test_generator, steps=test_generator.samples // test_generator.batch_size + 1)\n",
    "predicted_classes = np.where(predictions > 0.5, 1, 0)\n",
    "\n",
    "# Get the true labels\n",
    "true_classes = test_generator.classes\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "print(report)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alexnet model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 556 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\swadh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 362ms/step - accuracy: 0.8890 - loss: 0.2783\n",
      "Test Loss: 0.3514704704284668, Test Accuracy: 0.8381295204162598\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 377ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  test_crime       0.81      0.94      0.87       330\n",
      " test_normal       0.89      0.69      0.78       226\n",
      "\n",
      "    accuracy                           0.84       556\n",
      "   macro avg       0.85      0.81      0.82       556\n",
      "weighted avg       0.85      0.84      0.83       556\n",
      "\n",
      "[[311  19]\n",
      " [ 71 155]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('C:/Users/swadh/OneDrive/Desktop/crimedetection/alexnet.h5')\n",
    "\n",
    "# Define the test data generator\n",
    "IMAGE_RESIZE = (240, 320)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "test_data_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create a generator for the test data\n",
    "test_generator = test_data_generator.flow_from_directory(\n",
    "    r'C:\\Users\\swadh\\OneDrive\\Desktop\\crimedetection',\n",
    "    target_size=IMAGE_RESIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    classes=['test_crime', 'test_normal'],\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "evaluation = model.evaluate(test_generator)\n",
    "print(f\"Test Loss: {evaluation[0]}, Test Accuracy: {evaluation[1]}\")\n",
    "\n",
    "# Predict the test data\n",
    "test_generator.reset()\n",
    "preds = model.predict(test_generator, steps=test_generator.samples // BATCH_SIZE + 1)\n",
    "predicted_classes = (preds > 0.5).astype(\"int32\").flatten()\n",
    "\n",
    "# Get the ground truth\n",
    "true_classes = test_generator.classes\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Print classification report\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "print(report)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "print(conf_matrix)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 556 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\swadh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 330ms/step - accuracy: 0.8800 - loss: 0.2651\n",
      "Test Loss: 0.24591591954231262, Test Accuracy: 0.8902877569198608\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 312ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  test_crime       0.92      0.90      0.91       330\n",
      " test_normal       0.85      0.88      0.87       226\n",
      "\n",
      "    accuracy                           0.89       556\n",
      "   macro avg       0.89      0.89      0.89       556\n",
      "weighted avg       0.89      0.89      0.89       556\n",
      "\n",
      "[[296  34]\n",
      " [ 27 199]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('C:/Users/swadh/OneDrive/Desktop/crimedetection/self.h5')\n",
    "\n",
    "# Define the test data generator\n",
    "IMAGE_RESIZE = (240, 320)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "test_data_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create a generator for the test data\n",
    "test_generator = test_data_generator.flow_from_directory(\n",
    "    r'C:\\Users\\swadh\\OneDrive\\Desktop\\crimedetection',\n",
    "    target_size=IMAGE_RESIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    classes=['test_crime', 'test_normal'],\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "evaluation = model.evaluate(test_generator)\n",
    "print(f\"Test Loss: {evaluation[0]}, Test Accuracy: {evaluation[1]}\")\n",
    "\n",
    "# Predict the test data\n",
    "test_generator.reset()\n",
    "preds = model.predict(test_generator, steps=test_generator.samples // BATCH_SIZE + 1)\n",
    "predicted_classes = (preds > 0.5).astype(\"int32\").flatten()\n",
    "\n",
    "# Get the ground truth\n",
    "true_classes = test_generator.classes\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Print classification report\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "print(report)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "print(conf_matrix)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
