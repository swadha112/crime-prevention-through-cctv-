the UCF Avenue dataset was utilized, which contains videos of various anomalies, including different types of crimes, as shown in Table 6, to develop a crime detection model. The dataset, known for its challenging nature, provided a rich source of video data featuring both normal and anomalous activities. To effectively leverage this data, initially frames were extracted from the videos, a critical step in converting the video content into a format suitable for training the models. For frame extraction, DeepStack, an AI server that allowed us to process the video content efficiently was used. The interval rate was set at 30 frames per second, which was chosen to balance the need for detailed analysis with the computational resources available. This interval ensures that significant movements and actions were captured within the video without overwhelming the system with redundant frames. Additionally, a confidence level of 70% was applied for the frame extraction process. This confidence level was selected to filter out frames that might contain ambiguous or non-relevant content, thereby improving the quality of the dataset and ensuring that only frames with a high likelihood of containing actionable information were included. After extraction, the frames were preprocessed to a resolution of 240 by 320 pixels. This resizing was done to standardize the input dimensions across all frames, making the data more manageable and ensuring compatibility with various machine learning models. Preprocessing in this manner is essential to maintaining consistency in input data, which directly impacts the accuracy and efficiency of model training. To further enhance the dataset, several data augmentation techniques were applied. This step was crucial in increasing the diversity of the training data, which helps in building a more robust model capable of generalizing better to unseen data. While this work explored the use of Generative Adversarial Networks (GANs) for data augmentation, it was found that the low-quality images generated by the GANs did not contribute positively to the model's performance. As a result, it only focused on traditional augmentation methods, such as rotations, flips, and brightness adjustments, which provided better results. The preprocessed and augmented frames were then processed in batches and used to train and compile models across various architectures, including ResNet50, VGG16, VGG19, AlexNet, and a custom-designed model.
